# Projeto MVP - Sprint 3 - Engenharia de Dados - PUC-RIO

## Sobre Mim

- **Nome:** Paulo Henrique Lima da Silva
- **RA:** 4052023000752
- **Turma:** 40530010002_20230_02
- **GitHub:** [@pitarac](https://www.github.com/pitarac)

# Meu Pipeline de Dados na Nuvem usando Google Cloud e Objetivo

Olá pessoal! Meu nome é Paulo Leocádia e neste projeto de Engenharia de Dados, estou construindo um pipeline poderoso na nuvem usando o Google Cloud. Meu objetivo é coletar, modelar, carregar e analisar dados de forma eficiente para obter insights valiosos.

[Leia mais sobre o objetivo do MVP](https://github.com/pitarac/mvp-sprint-eng-de-dados/blob/main/objetivo.md)

## Fase 1: Busca pelos Dados
- **Descrição:** Nesta fase, busquei os dados que seriam a base do meu projeto.
- **Ferramentas do Google:** 
  - Utilizei o Google Cloud Storage para armazenar os dados brutos.

[Documentação detalhada da Fase 1](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-1)

## Fase 2: Coleta 
- **Descrição:** Aqui, coletei os dados do meu conjunto escolhido (eCommerce behavior data) e os inseri no Google Cloud Storage.
- **Ferramentas do Google:**
  - Utilizei o Google BigQuery para consultas e manipulação de dados.
  - Armazenei dados temporários no Google Cloud Storage.
  
[Documentação detalhada da Fase 2](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-2)

## Fase 3: Modelagem 
- **Descrição:** Nesta fase, trabalhei na modelagem de dados, onde defini o esquema de dados e criei um catálogo.
- **Ferramentas do Google:**
  - Utilizei o Google BigQuery para definir esquemas e criar tabelas.
  
[Documentação detalhada da Fase 3](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-3)

## Fase 4: Carga
- **Descrição:** Aqui, realizei a carga dos dados em um Data Warehouse/Data Lake.
- **Ferramentas do Google:**
  - Utilizei o Google Cloud Dataflow para ETL (Extração, Transformação e Carga).
  - Armazenei e consultei dados no Google BigQuery.
  
[Documentação detalhada da Fase 4](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-4)

## Fase 5: Análise
- **Descrição:** Nesta etapa, realizei análises de qualidade de dados e resolvi o problema definido inicialmente.
- **Ferramentas do Google:**
  - Utilizei o Google Data Studio para criar painéis de visualização.
  - Consultei dados complexos no Google BigQuery.
  
[Documentação detalhada da Fase 5](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-5)

## Autoavaliação
- Após a conclusão do pipeline, fiz uma autoavaliação crítica, avaliando eficiência, qualidade dos dados, escalabilidade e se alcancei as métricas e KPIs definidos no início do projeto.

Em resumo, meu pipeline de dados na nuvem com o Google Cloud é uma solução abrangente para adquirir, processar e analisar dados de maneira eficaz, permitindo decisões embasadas em dados precisos. Vou continuar aprimorando para atender às necessidades em constante evolução.

## Referências
- [Documentação do Google Cloud](https://cloud.google.com/docs)

