# Projeto MVP - Sprint 3 - Engenharia de Dados - PUC-RIO

## Autor (aluno)

- **Nome:** Paulo Henrique Lima da Silva
- **RA:** 4052023000752
- **Turma:** 40530010002_20230_02
- **GitHub:** [@pitarac](https://www.github.com/pitarac)

# Descrição do Meu Pipeline de Dados na Nuvem usando Google Cloud

Olá pessoal! Meu nome é Paulo Leocádia e neste projeto de Engenharia de Dados, estou construindo um pipeline poderoso na nuvem usando o Google Cloud. O objetivo é coletar, modelar, carregar e analisar dados de forma eficiente para obter insights valiosos.

[Leia mais sobre o objetivo do MVP](https://github.com/pitarac/mvp-sprint-eng-de-dados/blob/main/objetivo.md)

## Fase 1: Coleta de Dados
- Na primeira fase, estou usando serviços como o Google Cloud Storage e Dataflow para coletar dados de várias fontes, incluindo APIs, bancos de dados e feeds em tempo real. Criei fluxos de dados confiáveis para garantir uma coleta contínua.

[Documentação detalhada da Fase 1](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-1)

## Fase 2: Modelagem de Dados
- Para a modelagem de dados, contei com o Google BigQuery. Realizei limpeza, transformação e agregação para criar conjuntos de dados otimizados e estruturados para análise.

[Documentação detalhada da Fase 2](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-2)

## Fase 3: Carga de Dados
- Utilizei o Google Cloud Dataflow para a carga de dados, garantindo que eles estejam prontos para análise em tempo real ou sob demanda.

[Documentação detalhada da Fase 3](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-3)

## Fase 4: Análise de Dados
- A análise de dados foi conduzida usando ferramentas como Google Data Studio, Looker e notebooks Jupyter com Python. Explorei os dados, criei visualizações interativas e executei consultas avançadas para extrair insights valiosos.

[Documentação detalhada da Fase 4](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-4)

## Autoavaliação
- Após a conclusão do pipeline, fiz uma autoavaliação crítica, avaliando eficiência, qualidade dos dados, escalabilidade e se alcancei as métricas e KPIs definidos no início do projeto.

Em resumo, meu pipeline de dados na nuvem com o Google Cloud é uma solução abrangente para adquirir, processar e analisar dados de maneira eficaz, permitindo decisões embasadas em dados precisos. Vou continuar aprimorando para atender às necessidades em constante evolução.



## Referências

- [Awesome Readme Templates](https://awesomeopensource.com/project/elangosundar/awesome-README-templates)
- [Awesome README](https://github.com/matiassingers/awesome-readme)
- [Como Escrever um Bom README](https://bulldogjob.com/news/449-how-to-write-a-good-readme-for-your-github-project)
