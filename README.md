
# Projeto MVP - Sprint 3 - Engenharia de Dados - PUC- RIO 



## Autor (aluno)

- Paulo Henrique Lima da Silva 
- RA - 4052023000752
- Turma 40530010002_20230_02
- [@pitarac github](https://www.github.com/pitarac)

# Descrição do Meu Pipeline de Dados na Nuvem usando Google Cloud

Neste projeto de Engenharia de Dados, estou implementando um pipeline robusto e escalável na nuvem, utilizando a poderosa infraestrutura do Google Cloud. Meu objetivo é buscar, coletar, modelar, carregar e analisar dados de maneira eficiente, fornecendo insights valiosos para minhas tomadas de decisões informadas.

[Consultar objetivo do MVP](https://github.com/pitarac/mvp-sprint-eng-de-dados/blob/main/objetivo.md)

## Fase 1: Busca e Coleta de Dados
- Nesta etapa, estou usando serviços como o Google Cloud Storage e Dataflow para coletar dados de fontes diversas, como APIs, bancos de dados e feeds em tempo real. Implementei fluxos de dados que garantem a coleta contínua e confiável de informações.

Consulte aqui a documentação [Fase 1](https://github.com/pitarac/mvp-sprint-eng-de-dados/tree/main/fase-1)

## Fase 2: Modelagem de Dados
- Utilizei o Google BigQuery para modelar meus dados. Fiz a limpeza, transformação e agregação necessárias para criar conjuntos de dados estruturados e otimizados para análise. A modelagem de dados é crucial para garantir a qualidade e a integridade dos dados.

## Fase 3: Carga de Dados
- Utilizei o Google Cloud Dataflow, como o BigQuery ou Cloud SQL. Isso garantiu que meus dados estivessem prontos para análise em tempo real ou sob demanda.

## Fase 4: Análise de Dados
- A análise de dados foi realizada usando ferramentas como o Google Data Studio, Looker ou até mesmo notebooks Jupyter com Python. Aqui, explorei os dados, criei visualizações interativas e executei consultas avançadas para extrair insights relevantes.

## Autoavaliação:
- Após a conclusão do meu pipeline, realizei uma autoavaliação crítica. Avaliei a eficiência do pipeline, a qualidade dos dados, a escalabilidade e a capacidade de resposta às minhas necessidades de análise. Também avaliei se as métricas e os KPIs definidos no início do projeto foram alcançados.

Em resumo, meu pipeline de dados na nuvem com o Google Cloud é uma solução abrangente para adquirir, processar e analisar dados de maneira eficaz, permitindo que minha organização tome decisões embasadas em dados precisos e relevantes. Vou manter um ciclo contínuo de aprimoramento para garantir que meu pipeline esteja sempre atendendo às minhas necessidades em constante evolução.





## Referência

 - [Awesome Readme Templates](https://awesomeopensource.com/project/elangosundar/awesome-README-templates)
 - [Awesome README](https://github.com/matiassingers/awesome-readme)
 - [How to write a Good readme](https://bulldogjob.com/news/449-how-to-write-a-good-readme-for-your-github-project)

