{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pitarac/mvp-sprint-eng-de-dados/blob/main/fase-5/notebook\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Análise das Principais Métricas de E-commerce**\n",
        "\n",
        "O objetivo deste notebook é analisar os principais indicadores de desempenho da loja e também encontrar insights a partir dos dados que podem ajudar a loja a melhorar sua receita e metas de desempenho.\n",
        "\n",
        "Aqui estão algumas das perguntas que vou responder:\n",
        "- **Top 10 Produtos com Maior Faturamento**\n",
        "- **Top 10 Produtos por Lucro por Sessão**\n",
        "- **Top 10 Produtos por Taxas de Conversão**\n",
        "\n",
        "\n",
        "Se você encontrar algum erro na minha lógica, redundância no código, tiver algumas dicas para compartilhar ou simplesmente quiser bater um papo, por favor, entre em contato, estou ansioso para ouvir de você.\n",
        "\n",
        "Agora, sem mais delongas, vamos mergulhar no notebook.\n"
      ],
      "metadata": {
        "id": "jqoWnYu5I9hg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando Bibliotecas e Preparando os Dados\n",
        "\n",
        "Primeiro, vamos importar algumas bibliotecas Python bem conhecidas para nos ajudar a analisar todos esses dados. Em seguida, vamos carregar tudo em um DataFrame chamado `raw_events_data`.\n",
        "\n",
        "Infelizmente, este conjunto de dados é extremamente grande (+14GB com mais de 100 milhões de linhas), e o kernel sempre ficava sem memória ao tentar carregar tantos dados. Portanto, para fins desta análise, trabalharemos apenas com as primeiras 10 milhões de linhas do arquivo de outubro de 2019. No entanto, todo o código permanece o mesmo, independentemente de quantas linhas você queira analisar.\n"
      ],
      "metadata": {
        "id": "VTX8uL0oDFGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import gc\n",
        "import os\n",
        "\n",
        "# Fazendo o download dos arquivos do Google Cloud Storage para a máquina local\n",
        "os.system('gsutil -m cp \"gs://mpvsprint3/2019-Nov.csv\" .')\n",
        "os.system('gsutil -m cp \"gs://mpvsprint3/2019-Oct.csv\" .')\n",
        "\n",
        "# Carregando os dados em um DataFrame pandas\n",
        "raw_events_data = pd.read_csv('2019-Nov.csv', parse_dates=['event_time'], nrows=10000000)\n",
        "raw_events_data.info()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:17:25.203825Z",
          "iopub.execute_input": "2022-04-12T14:17:25.204152Z",
          "iopub.status.idle": "2022-04-12T14:20:18.115881Z",
          "shell.execute_reply.started": "2022-04-12T14:17:25.204122Z",
          "shell.execute_reply": "2022-04-12T14:20:18.114732Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "UoQgf72mDFGs",
        "outputId": "8402f7d7-eab9-4c51-8d29-c09576f79e84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ad12fd3d7d85>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Carregando os dados em um DataFrame pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mraw_events_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2019-Nov.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'event_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mraw_events_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2019-Nov.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparando os Dados\n",
        "\n",
        "Atualmente, a tabela com a qual estamos trabalhando (`raw_events_data`) armazena todas as informações dos produtos, sessões do site e eventos do site.\n",
        "\n",
        "\n",
        "Infelizmente, a forma como esta tabela está estruturada leva ao armazenamento de muitos dados redundantes, tornando nossa análise muito mais lenta e dificultando a compreensão dos dados.\n",
        "\n",
        "Então, antes de realmente começarmos a buscar insights, vamos transformar essa grande tabela desajeitada em 3 menores, aplicando alguns princípios de normalização.\n",
        "\n",
        "Depois de normalizarmos a tabela, acabaremos com 3 tabelas diferentes, que são:\n",
        "1. `products`: Armazena informações únicas dos produtos\n",
        "2. `user_sessions`: Armazena informações únicas das sessões do site\n",
        "3. `events`: Armazena informações únicas dos eventos do site\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hh8v2rcnDFGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RiJZ6wDYGJgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Criando as Tabelas\n",
        "\n",
        "## Tabela `products`\n",
        "python\n",
        "products = raw_events_data[['product_id', 'category_id', 'category_code', 'brand', 'price']].drop_duplicates()\n",
        "products.set_index('product_id', inplace=True)\n",
        "\n",
        "\n",
        "## Tabela `user_sessions`\n",
        "python\n",
        "user_sessions = raw_events_data[['user_session', 'user_id']].drop_duplicates()\n",
        "user_sessions.set_index('user_session', inplace=True)\n",
        "\n",
        "\n",
        "## Tabela `events`\n",
        "python\n",
        "events = raw_events_data[['event_time', 'event_type', 'product_id', 'user_session']]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:20:18.118155Z",
          "iopub.execute_input": "2022-04-12T14:20:18.11865Z",
          "iopub.status.idle": "2022-04-12T14:20:29.564223Z",
          "shell.execute_reply.started": "2022-04-12T14:20:18.118599Z",
          "shell.execute_reply": "2022-04-12T14:20:29.563503Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "evlmafVADFGt",
        "outputId": "9db05fe7-a765-468a-fd00-19e66c25885d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-631c4c692cc8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## Tabela `products`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_events_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'category_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'category_code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'brand'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que temos 3 tabelas diferentes seguindo princípios padrões de normalização - em vez de um conjunto de dados grande e desajeitado - vamos descobrir quanto de memória conseguimos economizar.\n"
      ],
      "metadata": {
        "id": "mk_EWa2FDFGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo o uso total de memória das 3 tabelas normalizadas pelo uso de memória da tabela com a qual começamos nossa análise\n",
        "\n",
        "```python\n",
        "comparative_memory_usage = round((1-(user_sessions.memory_usage().sum() + products.memory_usage().sum() + events.memory_usage().sum())/raw_events_data.memory_usage().sum())*100,2)\n",
        "\n",
        "del raw_events_data\n",
        "gc.collect()\n",
        "\n",
        "print(f\"As 3 tabelas normalizadas nos ajudam a economizar {comparative_memory_usage}% em espaço!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:20:29.565687Z",
          "iopub.execute_input": "2022-04-12T14:20:29.56594Z",
          "iopub.status.idle": "2022-04-12T14:20:29.835933Z",
          "shell.execute_reply.started": "2022-04-12T14:20:29.56591Z",
          "shell.execute_reply": "2022-04-12T14:20:29.834786Z"
        },
        "trusted": true,
        "id": "4oektb2dDFGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como você pode ver, economizamos muito espaço, o que será muito útil para esta loja de e-commerce se ela quiser dimensionar o banco de dados e começar a armazenar outros pontos de dados (como fontes de tráfego, custo dos produtos vendidos, etc).\n",
        "\n",
        "E agora que preparamos os dados, vamos finalmente começar a analisar os números em busca de insights.\n",
        "\n",
        "***\n",
        "\n",
        "## Inteligência de Produto\n",
        "\n",
        "### Produto Mais Rentável\n",
        "\n",
        "Para começar nossa análise, vamos descobrir quais são os 10 produtos mais rentáveis da nossa loja, ou seja, os produtos que geram a maior quantidade de dinheiro em termos de receita...\n"
      ],
      "metadata": {
        "id": "0gQCBRQmDFGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Mesclar a tabela `events` com a tabela `products`\n",
        "# 2) Agrupar todos os eventos de compra pelo `product_id`\n",
        "# 3) Somar o preço de todas as suas vendas\n",
        "\n",
        "events_on_products = events.merge(products, how='left', left_on = 'product_id', right_index=True)\n",
        "events_on_products[events_on_products['event_type'] == 'purchase'][['product_id', 'price']].groupby(by='product_id').sum().sort_values(by='price', ascending=False).head(10).plot(kind='bar', title='Top 10 Produtos Por Receita', xlabel='Product_id', ylabel='Receita Total ($)')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:20:29.837886Z",
          "iopub.execute_input": "2022-04-12T14:20:29.838161Z",
          "iopub.status.idle": "2022-04-12T14:21:05.03728Z",
          "shell.execute_reply.started": "2022-04-12T14:20:29.83813Z",
          "shell.execute_reply": "2022-04-12T14:21:05.036214Z"
        },
        "trusted": true,
        "id": "BSkwHLqADFGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Maior Lucro por Sessão\n",
        "\n",
        "Agora, a receita total não é uma métrica significativa por si só, especialmente se ignorarmos o número de sessões que chegaram à página do produto.\n",
        "\n",
        "Afinal, se você está enviando muito tráfego para uma página que não está convertendo bem os usuários, pode estar deixando dinheiro na mesa facilmente.\n",
        "\n",
        "Portanto, para levar em conta o fato de que diferentes produtos têm diferentes taxas de conversão, vamos descobrir quais são os top 10 produtos por lucro por sessão.\n"
      ],
      "metadata": {
        "id": "G_9311hIDFGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1) Criei um DataFrame para descobrir o número total de visualizações por product_id\n",
        "\n",
        "\n",
        "num_of_views = pd.DataFrame(\n",
        "    data=events_on_products[events_on_products['event_type'] == 'view']['product_id'].value_counts()\n",
        ")\n",
        "num_of_views.rename(columns={'product_id': 'total_views'}, inplace=True)\n",
        "\n",
        "\n",
        "# 2) Criei um DataFrame para descobrir quanto cada produto gerou em receita\n",
        "\n",
        "\n",
        "revenue_per_product = events_on_products[events_on_products['event_type'] == 'purchase'][['product_id', 'price']].groupby(by='product_id').sum().sort_values(by='price', ascending=False)\n",
        "revenue_per_product.rename(columns={'price': 'total_revenue'}, inplace=True)\n",
        "\n",
        "\n",
        "# 3) Mesclando os dois DataFrames acima para agrupar produtos por seu ID, e depois dividindo a receita total pelo número de visualizações\n",
        "\n",
        "\n",
        "revenue_and_views = revenue_per_product.merge(num_of_views, left_index=True, right_index=True)\n",
        "revenue_per_view = revenue_and_views['total_revenue'] / revenue_and_views['total_views']\n",
        "\n",
        "revenue_per_view.sort_values(ascending=False).head(10).plot(kind='bar', title='Top 10 Produtos por Lucro por Sessão', xlabel='Product_id', ylabel='Lucro Médio por Sessão ($)')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:21:05.038708Z",
          "iopub.execute_input": "2022-04-12T14:21:05.039055Z",
          "iopub.status.idle": "2022-04-12T14:21:27.35578Z",
          "shell.execute_reply.started": "2022-04-12T14:21:05.039014Z",
          "shell.execute_reply": "2022-04-12T14:21:27.355204Z"
        },
        "trusted": true,
        "id": "rD7BJ_HODFGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taxas de Conversão por Produto\n",
        "\n",
        "Também podemos descobrir quais são os produtos com as maiores taxas de conversão, já que esses produtos também podem valer a pena direcionar tráfego para eles, e seus designs de página de destino podem ser usados como controles em testes A/B.\n",
        "\n",
        "Então, vamos descobrir quais são os top 10 produtos com as maiores taxas de conversão.\n"
      ],
      "metadata": {
        "id": "5MSyXS-dDFGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1) Descobri quantas vendas cada produto fez\n",
        "\n",
        "\n",
        "num_of_sales = pd.Series(events_on_products[events_on_products['event_type'] == 'purchase']['product_id'].value_counts())\n",
        "num_of_sales.rename('total_sales', inplace=True)\n",
        "\n",
        "\n",
        "# 2) Agrupei o número de visualizações e o número de vendas pelo `product_id`\n",
        "\n",
        "\n",
        "product_data = revenue_and_views.merge(num_of_sales, right_index=True, left_index=True)\n",
        "\n",
        "\n",
        "# 3) Dividi o número de vendas pelo número de visualizações e descobri a taxa de conversão de todos os produtos\n",
        "\n",
        "\n",
        "cvr = pd.Series(product_data['total_sales'] / product_data['total_views'])\n",
        "top_10_cvr = cvr.sort_values(ascending=False).head(10)\n",
        "top_10_cvr.plot(kind='bar', title='Top 10 Produtos por Taxas de Conversão', xlabel='Product_id', ylabel='Taxa de Conversão (de 0 a 1)')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:21:27.356921Z",
          "iopub.execute_input": "2022-04-12T14:21:27.357375Z",
          "iopub.status.idle": "2022-04-12T14:21:35.330745Z",
          "shell.execute_reply.started": "2022-04-12T14:21:27.357341Z",
          "shell.execute_reply": "2022-04-12T14:21:35.329728Z"
        },
        "trusted": true,
        "id": "qwIDyLr6DFGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como você pode ver, esses produtos têm uma taxa de conversão de 100%, e isso não é um erro no código ou na análise.\n",
        "\n",
        "Isso aconteceu porque esses produtos têm apenas 1 evento de visualização no período de análise e, por sorte, essa visualização resultou em uma compra. No entanto, se pudéssemos carregar mais dados, estou certo de que esse padrão não se manteria verdadeiro.\n"
      ],
      "metadata": {
        "id": "tpVPGhuPDFGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Produtos que Vendem Bem Juntos\n",
        "\n",
        "Ofertas adicionais, ofertas reduzidas e vendas cruzadas são uma das maneiras mais confiáveis de aumentar o valor médio do carrinho do cliente.\n",
        "\n",
        "Mas, para otimizá-los, os produtos oferecidos não podem ser escolhidos aleatoriamente. Afinal, cada produto atende a diferentes perfis de clientes, e tentar usar uma abordagem única para todos na jornada de venda adicional é uma maneira garantida de deixar dinheiro na mesa.\n",
        "\n",
        "Então, vamos analisar os dados e descobrir quais produtos os usuários costumam comprar na mesma sessão.\n"
      ],
      "metadata": {
        "id": "OeEjMTL2DFGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Juntei a tabela user_sessions com a tabela events\n",
        "\n",
        "sessions_on_events = user_sessions.merge(events, how='left', left_on='user_session', right_on='user_session')\n",
        "\n",
        "# 2) Filtrando a tabela acima em busca de eventos de compra e, em seguida, contei o número de itens comprados por sessão de usuário\n",
        "\n",
        "items_bought_per_session = pd.DataFrame(sessions_on_events[sessions_on_events['event_type'] == 'purchase']['user_session'].value_counts())\n",
        "items_bought_per_session.reset_index(inplace=True)\n",
        "items_bought_per_session.rename(columns={'user_session': 'items_bought', 'index': 'user_session'}, inplace=True)\n",
        "items_bought_per_session.head(5)\n",
        "\n",
        "# 3) Criei uma tabela com sessões que tiveram mais de 1 item comprado\n",
        "\n",
        "session_purchases = items_bought_per_session[items_bought_per_session['items_bought'] >= 2].merge(\n",
        "    sessions_on_events[sessions_on_events['event_type'] == 'purchase'],\n",
        "    how='left',\n",
        "    left_on='user_session',\n",
        "    right_on='user_session')[['user_session', 'items_bought', 'product_id']]\n",
        "\n",
        "# 4) Agrupei em um conjunto todos os produtos (por id) comprados em cada uma das sessões de usuário em que o número de itens comprados foi maior que 1.\n",
        "\n",
        "# Agrupei todos os produtos comprados por sessão em um conjunto porque - ao contrário de uma lista - a ordem dos itens não importa.\n",
        "# Portanto, se um cliente comprou primeiro o produto X e depois o produto Y, ou vice-versa, não fará diferença na análise.\n",
        "# E vale ressaltar que os conjuntos não armazenam valores repetidos... Portanto, desde que o usuário compre mais de 1 item, a quantidade comprada também não afetará a análise.\n",
        "\n",
        "# Admito que o código abaixo fica um pouco complicado, se você souber de uma maneira mais fácil de fazer essa tarefa, por favor, entre em contato.\n",
        "\n",
        "sessoes_analisadas = []\n",
        "combinacoes_venda_cruzada_brutas = []\n",
        "for user_session in session_purchases['user_session']:\n",
        "    produtos_comprados_por_id = []\n",
        "    if user_session in sessoes_analisadas:\n",
        "        pass\n",
        "    else:\n",
        "        nparray_produtos_comprados = (session_purchases[session_purchases['user_session'] == user_session]['product_id'].values)\n",
        "        lista_produtos_comprados = nparray_produtos_comprados.tolist()\n",
        "        produtos_comprados_por_id.append(set(lista_produtos_comprados))\n",
        "        combinacoes_venda_cruzada_brutas.append(produtos_comprados_por_id)\n",
        "        sessoes_analisadas.append(user_session)\n",
        "\n",
        "# 5) Importei o módulo itertools para organizar os conjuntos (que referenciam os produtos comprados de cada sessão) em uma lista\n",
        "\n",
        "from itertools import chain\n",
        "combinacoes_venda_cruzada = list(chain.from_iterable(combinacoes_venda_cruzada_brutas))\n",
        "\n",
        "# 6) Por fim, contei o número de vendas de cada conjunto de produtos e descobri quais são os 10 melhores\n",
        "\n",
        "num_de_vendas_cruzadas = pd.DataFrame(pd.Series(combinacoes_venda_cruzada).value_counts())\n",
        "num_de_vendas_cruzadas.reset_index(inplace=True)\n",
        "num_de_vendas_cruzadas.rename(columns={'index': 'produtos_comprados', 0: 'num_de_vendas'}, inplace=True)\n",
        "num_de_vendas_cruzadas.head(10).plot(kind='bar', x='produtos_comprados', xlabel='Produtos Comprados na Mesma Sessão', ylabel='Número de Compras', title='Top 10 Produtos por Número de Vendas Cruzadas')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:21:35.332194Z",
          "iopub.execute_input": "2022-04-12T14:21:35.332713Z",
          "iopub.status.idle": "2022-04-12T14:26:14.078628Z",
          "shell.execute_reply.started": "2022-04-12T14:21:35.33268Z",
          "shell.execute_reply": "2022-04-12T14:26:14.077602Z"
        },
        "trusted": true,
        "id": "jZadBKkzDFGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E essas foram as grupos de produtos com a maior quantidade de cross-sells.\n",
        "\n",
        "Como você provavelmente já percebeu, a maioria desses grupos é composta por apenas um produto.\n",
        "\n",
        "Já que filtramos apenas as sessões em que mais de um item foi comprado, isso indica que os clientes compraram apenas um produto em uma determinada sessão, mas acabaram comprando vários itens desses mesmos produtos.\n",
        "\n",
        "Portanto, o caminho de upsell mais comum parece ser oferecer mais do mesmo, em vez de oferecer produtos diferentes.\n",
        "\n",
        "Caso você esteja curioso, também podemos descobrir quais são os pacotes de produtos reais (ou seja, aqueles com 2 produtos diferentes comprados) com a maior quantidade de vendas.\n",
        "\n",
        "<h3> Pacotes de Produtos Mais Vendidos </h3>"
      ],
      "metadata": {
        "id": "AO4nY_ZDDFGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Iterar sobre a tabela num_of_cross_sales e descobrir quais são os conjuntos com len() > 1 (ou seja, indicando que vários produtos diferentes foram comprados na mesma sessão de usuário)\n",
        "\n",
        "vendas_cruzadas = []\n",
        "for conjunto in num_of_cross_sales['products_bought']:\n",
        "    if len(conjunto) > 1:\n",
        "        vendas_cruzadas.append(conjunto)\n",
        "\n",
        "# 2) Organizar os conjuntos em um DataFrame e contar quantas vezes eles aparecem\n",
        "\n",
        "vendas_cruzadas = pd.DataFrame(pd.Series(vendas_cruzadas).value_counts())\n",
        "vendas_cruzadas.reset_index(inplace=True)\n",
        "vendas_cruzadas.rename(columns={'index':'conjunto_de_produtos',0:'num_de_vendas'},inplace=True)\n",
        "vendas_cruzadas.sort_values(by='num_de_vendas',ascending=False).head(10).plot(kind='bar',x='conjunto_de_produtos')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:26:14.080088Z",
          "iopub.execute_input": "2022-04-12T14:26:14.080366Z",
          "iopub.status.idle": "2022-04-12T14:26:22.269392Z",
          "shell.execute_reply.started": "2022-04-12T14:26:14.080331Z",
          "shell.execute_reply": "2022-04-12T14:26:22.268678Z"
        },
        "trusted": true,
        "id": "E_qN6uL9DFGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como você pode ver, esses são os produtos que - quando combinados - os usuários demonstraram comprar mais.\n",
        "\n",
        "Essas informações são inestimáveis para os gerentes de lojas projetarem caminhos de upsell de alto desempenho para seus produtos. Talvez adicionando um pedido adicional ou um botão fácil de adicionar ao carrinho quando os usuários comprarem um desses produtos."
      ],
      "metadata": {
        "id": "QbgQVROSDFGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Valor Médio do Pedido</h3>\n",
        "\n",
        "Agora, falando sobre upsells e cross-sells, também podemos usar os dados para descobrir qual é o valor médio do pedido.\n",
        "\n",
        "Então, vamos descobrir:"
      ],
      "metadata": {
        "id": "neSouBetDFGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Juntei a tabela de produtos (products) com a tabela sessions_on_events para agrupar os produtos comprados por cada sessão de usuário individual\n",
        "\n",
        "produtos_comprados_por_sessao = sessions_on_events[sessions_on_events['event_type'] == 'purchase'][['user_session', 'product_id']]\n",
        "sessao_e_preco = produtos_comprados_por_sessao.merge(products, how='left', left_on='product_id', right_on='product_id')[['user_session', 'price']]\n",
        "\n",
        "# 2) Agrupei por user_session e somei o preço dos produtos comprados\n",
        "\n",
        "soma_produtos_comprados_por_sessao = sessao_e_preco.groupby(by='user_session').sum()\n",
        "soma_produtos_comprados_por_sessao.sort_values(by='price', ascending=False)\n",
        "\n",
        "# 3) Dividi o preço de todos os produtos comprados pelo número de sessões que resultaram em uma compra\n",
        "\n",
        "aov = soma_produtos_comprados_por_sessao.sum() / len(soma_produtos_comprados_por_sessao.index)\n",
        "\n",
        "print(f\"O Valor Médio do Pedido (Average Order Value - AOV) de cada compra é {aov}!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:26:22.270861Z",
          "iopub.execute_input": "2022-04-12T14:26:22.271318Z",
          "iopub.status.idle": "2022-04-12T14:26:25.136482Z",
          "shell.execute_reply.started": "2022-04-12T14:26:22.271284Z",
          "shell.execute_reply": "2022-04-12T14:26:25.135355Z"
        },
        "trusted": true,
        "id": "moRubHmzDFGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Número de Compras por Cliente</h3>\n",
        "\n"
      ],
      "metadata": {
        "id": "EOKNM4nPDFGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Realizei um left join do user_id na tabela session_and_price para contar os valores únicos\n",
        "\n",
        "sessoes_de_compra_e_clientes = session_and_price.merge(user_sessions, how='left', left_on='user_session', right_index=True)\n",
        "\n",
        "# 2) Dividi o número de sessões únicas que resultaram em uma compra pelo número de clientes\n",
        "\n",
        "compras_por_cliente = sessoes_de_compra_e_clientes['user_session'].nunique() / sessoes_de_compra_e_clientes['user_id'].nunique()\n",
        "\n",
        "print(f\"A média de compras por cliente é {compras_por_cliente}!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:26:25.139612Z",
          "iopub.execute_input": "2022-04-12T14:26:25.139956Z",
          "iopub.status.idle": "2022-04-12T14:26:27.299275Z",
          "shell.execute_reply.started": "2022-04-12T14:26:25.139913Z",
          "shell.execute_reply": "2022-04-12T14:26:27.298217Z"
        },
        "trusted": true,
        "id": "pvRENkRCDFGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Valor do Tempo de Vida do Cliente</h3>\n",
        "O Valor do Tempo de Vida do Cliente (Customer Lifetime Value - LTV) é uma métrica importante para avaliar o valor que um cliente médio traz para o seu negócio ao longo do tempo. É uma medida fundamental para entender o retorno do investimento em aquisição de clientes e para desenvolver estratégias de retenção de clientes."
      ],
      "metadata": {
        "id": "L-s_4o1mDFGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Descobri quanto cada cliente gastou na loja\n",
        "\n",
        "total_gasto_por_usuario = purchase_sessions_and_customers[['user_id', 'price']].groupby(by='user_id').sum().sort_values(by='price', ascending=False)\n",
        "\n",
        "# 2) Dividi o total gasto pelo número de clientes\n",
        "\n",
        "ltv = total_gasto_por_usuario.sum() / len(total_gasto_por_usuario.index)\n",
        "\n",
        "print(f\"O Valor do Tempo de Vida do Cliente (LTV) é {ltv}!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T14:26:27.300425Z",
          "iopub.execute_input": "2022-04-12T14:26:27.300635Z",
          "iopub.status.idle": "2022-04-12T14:26:27.398416Z",
          "shell.execute_reply.started": "2022-04-12T14:26:27.30061Z",
          "shell.execute_reply": "2022-04-12T14:26:27.397459Z"
        },
        "trusted": true,
        "id": "JH88FPucDFGw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}